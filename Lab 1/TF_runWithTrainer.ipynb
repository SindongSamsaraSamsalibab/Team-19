{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb749750-4bd2-40c2-a14a-1036f302944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oscar\\SKOLA\\D7047e\\Team-19\\Lab 1\n",
      "c:\\Users\\oscar\\SKOLA\\D7047e\\Team-19\\Lab 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_10940\\2845266932.py:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"amazon_cells_labelled.txt\", \"r\") as file:\\n    for line in file:\\n        # Strip whitespace, split the sentence and label\\n        line = line.strip()\\n        if line:\\n            line = line.replace(\\'((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\\\.|$)){4}\\', \\'\\')\\n            line = line.replace(\\'[^\\\\w\\\\s]\\',\\'\\')\\n            line = line.replace(\\'\\\\d\\', \\'\\') \\n            line = line.replace(\\'\\t\\', \\'\\') \\n            labels.append(int(line[-1]))\\n            sentences.append(line[:len(line)-1])\\n    file.close()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import nltk\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('stopwords')\n",
    "print(os.getcwd())\n",
    "import importlib\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoConfig, AutoModelForSequenceClassification\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(os.getcwd())\n",
    "from transformers import BertForSequenceClassification\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "'''\n",
    "with open(\"amazon_cells_labelled.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        # Strip whitespace, split the sentence and label\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            line = line.replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '')\n",
    "            line = line.replace('[^\\w\\s]','')\n",
    "            line = line.replace('\\d', '') \n",
    "            line = line.replace('\\t', '') \n",
    "            labels.append(int(line[-1]))\n",
    "            sentences.append(line[:len(line)-1])\n",
    "    file.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d837246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bertbert = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(bertbert)\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertbert)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(bertbert, num_labels=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1325ee13-b828-4a06-a352-59d8a83724f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Download latest version\\npath = kagglehub.dataset_download(\"mohamedbakhet/amazon-books-reviews\")\\n\\nprint(\"Path to dataset files:\", path)\\n\\n#PATH\\nfilepath = \\'/root/.cache/kagglehub/datasets/mohamedbakhet/amazon-books-reviews/versions/1/Books_rating.csv\\'\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Download latest version\n",
    "path = kagglehub.dataset_download(\"mohamedbakhet/amazon-books-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "#PATH\n",
    "filepath = '/root/.cache/kagglehub/datasets/mohamedbakhet/amazon-books-reviews/versions/1/Books_rating.csv'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1a193",
   "metadata": {},
   "source": [
    "Load dataset, extract only relevant data and split into datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "584d3010-ef5f-4c8b-9e2f-7c6171835502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1882931173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_id</th>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profileName</th>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review/helpfulness</th>\n",
       "      <td>7/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review/score</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review/time</th>\n",
       "      <td>940636800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review/summary</th>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review/text</th>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0\n",
       "Id                                                         1882931173\n",
       "Title                                  Its Only Art If Its Well Hung!\n",
       "Price                                                             NaN\n",
       "User_id                                                 AVCGYZL8FQQTD\n",
       "profileName                                     Jim of Oz \"jim-of-oz\"\n",
       "review/helpfulness                                                7/7\n",
       "review/score                                                      4.0\n",
       "review/time                                                 940636800\n",
       "review/summary                 Nice collection of Julie Strain images\n",
       "review/text         This is only for Julie Strain fans. It's a col..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 700/700 [00:00<00:00, 3345.53 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 3629.88 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 3603.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Rename label column and convert to 0-indexed\\nfor ds in [train_ds, val_ds, test_ds]:\\n    ds = ds.rename_column(\"review/score\", \"labels\")\\n    ds = ds.map(lambda x: {\"labels\": x[\"labels\"] - 1})\\n    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Books_rating.csv')\n",
    "print(len(data))\n",
    "display(data[0:1].T)\n",
    "data = data[['review/text', 'review/score']].dropna() #Keep only relevant columns and drop missing data.\n",
    "data['review/score'] = data['review/score'].astype(int)\n",
    "data = data[data['review/score'].between(0, 5)]\n",
    "data = data.rename(columns={'review/score': 'labels'})\n",
    "data=data[0:1000]\n",
    "#print(data['review/score'][0:100])\n",
    "\n",
    "train_df, temp_df = train_test_split(data, test_size=0.3, stratify=data['labels'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['labels'], random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_ds = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"review/text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "# Apply tokenization\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "# Set format for PyTorch\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds.set_format(\"torch\", columns=cols)\n",
    "val_ds.set_format(\"torch\", columns=cols)\n",
    "test_ds.set_format(\"torch\", columns=cols)\n",
    "\n",
    "\"\"\"\n",
    "# Rename label column and convert to 0-indexed\n",
    "for ds in [train_ds, val_ds, test_ds]:\n",
    "    ds = ds.rename_column(\"review/score\", \"labels\")\n",
    "    ds = ds.map(lambda x: {\"labels\": x[\"labels\"] - 1})\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e70e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2ee8932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-base-5class</strong> at: <a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/hgvao6y8' target=\"_blank\">https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/hgvao6y8</a><br> View project at: <a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment' target=\"_blank\">https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250409_151203-hgvao6y8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\oscar\\SKOLA\\D7047e\\Team-19\\Lab 1\\wandb\\run-20250409_153616-y9xzks27</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/y9xzks27' target=\"_blank\">bert-base-6class</a></strong> to <a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment' target=\"_blank\">https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/y9xzks27' target=\"_blank\">https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/y9xzks27</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ertveh-4-lule-university-of-technology/amazon-books-reviews-sentiment/runs/y9xzks27?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2a368115970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"amazon-books-reviews-sentiment\", name=\"bert-base-6class\", reinit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83d05973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_10940\\204124960.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"wandb\",  # Log to wandb\n",
    "    push_to_hub=False,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision on CUDA\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c87679a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 23:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.122513</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.152066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.266500</td>\n",
       "      <td>1.000544</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.152066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.025400</td>\n",
       "      <td>0.937041</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.164762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=132, training_loss=1.084872375835072, metrics={'train_runtime': 1416.8885, 'train_samples_per_second': 1.482, 'train_steps_per_second': 0.093, 'total_flos': 276276530073600.0, 'train_loss': 1.084872375835072, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9408d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0047962665557861,\n",
       " 'eval_accuracy': 0.6133333333333333,\n",
       " 'eval_f1_macro': 0.15269709543568463,\n",
       " 'eval_runtime': 26.8216,\n",
       " 'eval_samples_per_second': 5.593,\n",
       " 'eval_steps_per_second': 0.373,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
